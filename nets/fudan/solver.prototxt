net: "net.prototxt"
# Do test before training
test_initialization: false
# Test every nth iteration
test_interval: 2000
# How many iterations per test
test_iter: 2000

# Base learning rate
base_lr: 0.001
# Policy for changing the learning rate - multiply by gamma every stepsize iterations
lr_policy: "step"
stepsize: 60000
gamma: 0.1
#stepvalue: 28000
#stepvalue: 40000
#stepvalue: 100000
#stepvalue: 175000
momentum: 0.9
# Regularization parameter for the weights
weight_decay: 0.00001

# Display training loss every nth iteration
display: 100
# After how many iterations to stop
max_iter: 200000

# Snapshot every nth iteration in the specified directory
snapshot: 5000
snapshot_prefix: "./snapshots/"

random_seed: 1701
# Display the loss averaged over the last average_loss iterations - this does not work for accuracy
average_loss: 200
#clip_gradients: 10

# GPU for the win!
solver_mode: GPU
